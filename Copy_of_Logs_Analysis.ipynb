{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "Copy of Logs_Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e175892-b153-4a33-adde-56b02f8ce653"
      },
      "source": [
        "I am working on this new logs anaylsis notebook. Hopefully it will be able to generate logs, training graph metrics, etc. with a few click of a button.  \n",
        "\n",
        "-Nathan Liang"
      ],
      "id": "5e175892-b153-4a33-adde-56b02f8ce653"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f99de2d3-9a42-46a1-9f1d-bcdabe05280f"
      },
      "source": [
        "import json\n",
        "import pandas as pd"
      ],
      "id": "f99de2d3-9a42-46a1-9f1d-bcdabe05280f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84bb1956-79b0-4975-a015-16f895e9268c",
        "outputId": "c6e5868c-9d2c-4daf-b5db-51f72a7aa212"
      },
      "source": [
        "run_env = 'run.env'\n",
        "with open(run_env, 'r') as f:\n",
        "    for line in f.readlines():\n",
        "        if \"DR_LOCAL_S3_MODEL_PREFIX=\" in line:\n",
        "            spl_pnt = '='\n",
        "            MODEL_PREFIX = line.partition(spl_pnt)[2]\n",
        "            MODEL_PREFIX = MODEL_PREFIX.replace('\\n','')\n",
        "            \n",
        "MODEL_PREFIX"
      ],
      "id": "84bb1956-79b0-4975-a015-16f895e9268c",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'rl-deepracer-1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dab507f9-7ab9-4213-9eb1-347663250b9d"
      },
      "source": [
        "metrics1_fname = 'data/minio/bucket/%s/metrics/TrainingMetrics.json' %MODEL_PREFIX\n",
        "metrics2_fname = 'data/minio/bucket/%s/metrics/TrainingMetrics_1.json' %MODEL_PREFIX"
      ],
      "id": "dab507f9-7ab9-4213-9eb1-347663250b9d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02f30790-2443-450e-9629-bec2676f1f57"
      },
      "source": [
        "def json_to_list(file):\n",
        "    file = file.replace(\"{\",\"[\")\n",
        "    file = file.replace(\"}\",\"]\")\n",
        "    #file = file.replace(', ', '], [')\n",
        "    file = file.replace('\"', '')\n",
        "    file = file.replace('[metrics: ',\"\")\n",
        "    file = file.replace(', version: 2.0, best_model_metric: progress]',\"\")\n",
        "    \n",
        "    file = file.replace('reward_score: ', '\"')\n",
        "    file = file.replace(', metric_time: ', '\",\"')\n",
        "    file = file.replace(', start_time: ', '\",\"')\n",
        "    file = file.replace(', elapsed_time_in_milliseconds: ', '\",\"')\n",
        "    file = file.replace(', episode: ', '\",\"')\n",
        "    file = file.replace(', trial: ', '\",\"')\n",
        "    file = file.replace(', phase: ', '\",\"')\n",
        "    file = file.replace(', completion_percentage: ', '\",\"')\n",
        "    file = file.replace(', episode_status: ', '\",\"')\n",
        "    file = file.replace(']', '\"]')\n",
        "    file = file.replace('\"]\"]', '\"]]')\n",
        "    #print(file)\n",
        "    return json.loads(file)"
      ],
      "id": "02f30790-2443-450e-9629-bec2676f1f57",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9e50f76a-d84e-4932-9df2-1c271eaf83c1",
        "outputId": "7a4da7a0-24c8-470f-d84b-1e6d6b2ef1fe"
      },
      "source": [
        "with open(metrics1_fname, 'r') as file1:\n",
        "    for line in file1:\n",
        "        metrics1 = json_to_list(line)\n",
        "with open(metrics2_fname, 'r') as file2:\n",
        "    for line in file2:\n",
        "        metrics2 = json_to_list(line)\n",
        "print(type(metrics1))"
      ],
      "id": "9e50f76a-d84e-4932-9df2-1c271eaf83c1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0dfd5bc-8b8f-4c06-8266-16b7a0c2bbdb"
      },
      "source": [
        "def parse_data(data_list):\n",
        "    training = []\n",
        "    evaluation = []\n",
        "    for d in range(len(data_list)):\n",
        "        if data_list[d][6] == 'training':\n",
        "            episode = float(data_list[d][4])\n",
        "            reward = float(data_list[d][0])\n",
        "            progress = float(data_list[d][7])\n",
        "            status = float(data_list[d][8])\n",
        "            elapsed_time = float(data_list[d][3])\n",
        "            training.append([episode, reward, status])\n",
        "        elif data_list[d][6] == 'evaluation':\n",
        "            episode = float(data_list[d][4])\n",
        "            reward = float(data_list[d][0])\n",
        "            progress = float(data_list[d][7])\n",
        "            elapsed_time = float(data_list[d][3])\n",
        "            status = float(data_list[d][8])\n",
        "            evaluation.append([episode, reward, status])\n",
        "            \n",
        "    return [training, evaluation]"
      ],
      "id": "e0dfd5bc-8b8f-4c06-8266-16b7a0c2bbdb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b239a6ca-644d-4cb5-8d65-e4b893332674"
      },
      "source": [
        "training_data1, evaluation_data1 = parse_data(metrics1)\n",
        "training_data2, evaluation_data2 = parse_data(metrics2)"
      ],
      "id": "b239a6ca-644d-4cb5-8d65-e4b893332674",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9a818e1f-b54c-4101-a434-e3ce53456baa",
        "outputId": "44fc9b2a-beed-4ff1-978a-c43c37c98a47"
      },
      "source": [
        "header = ['episode', 'reward', 'progress', 'elapsed_time', 'status']\n",
        "sim_df1 = pd.DataFrame(training_data1, columns=header)\n",
        "sim_df2 = pd.DataFrame(training_data2, columns=header)\n",
        "sim_df1"
      ],
      "id": "9a818e1f-b54c-4101-a434-e3ce53456baa",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d10bc855-9e82-420c-a722-8ac26a9cb134"
      },
      "source": [
        "def plot_reward_graph(df_slice_iterations=sim_df1, df_slice_entropy=trn_df_entropy):\n",
        "    font_size=16\n",
        "    if(len(df_slice_iterations)>0):\n",
        "        fig = plt.figure(figsize=(16, 10))\n",
        "        ax = plt.gca()  # gca stands for 'get current axis'\n",
        "        ax.xaxis.set_major_locator(MaxNLocator(integer=True))  # force integer labels on x-axis\n",
        "        ax2 = ax.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "\n",
        "        df_slice_entropy.plot(kind='line',x='iteration',y='avg_entropy',label='',linewidth=1,color='red',alpha=0.3,fontsize=font_size,ax=ax)\n",
        "        df_slice_entropy.plot(kind='line',linestyle='solid',x='iteration',y='avg_entropy_SMA3',linewidth=1.5,color='red',fontsize=font_size,ax=ax)\n",
        "\n",
        "        df_slice_iterations.plot(kind='line',x='iteration',y='total_rewards_normalized',label='',linewidth=1,color='green',alpha=0.3,fontsize=font_size,ax=ax2)\n",
        "        df_slice_iterations.plot(kind='line',linestyle='solid',x='iteration',y='total_rewards_normalized_SMA3',linewidth=1.5,color='green',fontsize=font_size,ax=ax2)\n",
        "\n",
        "        df_slice_iterations.plot(kind='line',x='iteration',y='avg_progress',label='',linewidth=1,color='blue',alpha=0.3,fontsize=font_size,ax=ax2)\n",
        "        df_slice_iterations.plot(kind='line',linestyle='dashdot',x='iteration',y='avg_progress_SMA3',linewidth=3,color='blue',fontsize=font_size,ax=ax2)\n",
        "\n",
        "        ax.legend().remove()\n",
        "        ax.set_xlabel(ax.get_xlabel(), fontsize=font_size)\n",
        "        ax.set_ylabel('Entropy', fontsize=font_size)\n",
        "\n",
        "        ax2.legend().remove()\n",
        "        ax2.set_ylabel('Normalized Rewards / Progress (%) / Completed Laps (%)', fontsize=font_size)\n",
        "\n",
        "        start_time = df_slice_iterations[\"start_time\"].min()\n",
        "        end_time = df_slice_iterations[\"end_time\"].max()\n",
        "        elapsed_time = end_time - start_time\n",
        "        elapsed_time_hrs = elapsed_time / 3600\n",
        "        plt.plot([], [], ' ', label='Iterations: %d' % df_slice_iterations[\"iteration\"].max())\n",
        "        plt.plot([], [], ' ', label='Elapsed Time: %0.2fhrs' % elapsed_time_hrs)\n",
        "\n",
        "        fig.legend(loc=\"lower center\", borderaxespad=0.1, ncol=4, fontsize=14, title=\"Legend\")\n",
        "        plt.subplots_adjust(bottom=0.15)\n",
        "\n",
        "        max_rewards_iter = df_slice_iterations['total_rewards_normalized_SMA3'].idxmax()\n",
        "        if (max_rewards_iter >= 0):\n",
        "            xmax_rewards = df_slice_iterations['iteration'][max_rewards_iter]\n",
        "            ymax_rewards = df_slice_iterations['total_rewards_normalized_SMA3'].max()\n",
        "            plt.axvline(x=xmax_rewards,linestyle='dotted',linewidth=0.75,color='black')\n",
        "            plt.axhline(y=ymax_rewards,linestyle='dotted',linewidth=0.75,color='black',alpha=0.3)\n",
        "            plt.gca().text(xmax_rewards*0.995, ymax_rewards*1.005, 'Max Rewards @ %d' % xmax_rewards, ha='right', va='bottom', size=font_size)\n",
        "\n",
        "        max_progress_iter = df_slice_iterations['avg_progress_SMA3'].idxmax()\n",
        "        if (max_progress_iter >= 0):\n",
        "            xmax_progress = df_slice_iterations['iteration'][max_progress_iter]\n",
        "            ymax_progress = df_slice_iterations['avg_progress_SMA3'].max()\n",
        "            plt.axvline(x=xmax_progress,linestyle='dotted',linewidth=0.75,color='black')\n",
        "            plt.axhline(y=ymax_progress,linestyle='dotted',linewidth=0.75,color='black',alpha=0.3)\n",
        "            plt.gca().text(xmax_progress*0.995, ymax_progress*1.005, 'Max Progress @ %d' % xmax_progress, ha='right', va='bottom', size=font_size)\n",
        "\n",
        "        plt.yticks(np.arange(0, 105, step=10))\n",
        "        plt.show()\n",
        "        if (max_rewards_iter >= 0):\n",
        "            print (\"Iteration with Max Total Rewards (SMA3): %d\" % (xmax_rewards))\n",
        "        print (\"Elapsed Time: %0.2fs (%0.2fhrs)\" % (elapsed_time, elapsed_time_hrs))\n",
        "\n",
        "\n",
        "plot_reward_graph()"
      ],
      "id": "d10bc855-9e82-420c-a722-8ac26a9cb134",
      "execution_count": null,
      "outputs": []
    }
  ]
}